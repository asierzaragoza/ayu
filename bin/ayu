#!/usr/bin/python3

import argparse
import os
import pickle
import pandas as pd
import ayu.preprocessing
import ayu.protein_features
import ayu.ilr_conversion
import ayu.ex_programs_processing


parser = argparse.ArgumentParser()
parser.add_argument('input_file', help='Fasta file')
parser.add_argument('out_dir', help='Output directory')
parser.add_argument('--threads', type=int, default=8, help='number of threads for features that allow multiprocessing (default=8)')
parser.add_argument('--run_signalp6')
parser.add_argument('--run_tmbed')
parser.add_argument('--signalp_file')
parser.add_argument('--tmbed_file')

args = parser.parse_args()
args.out_dir = args.out_dir.rstrip('/') + '/'

def find_ayu_status_file(ayu_dir):
    ayu_file_list = [x for x in os.listdir(ayu_dir) if x.split('.')[-1] == 'ayu']
    if len(ayu_file_list) == 1:
        return ayu_dir.out_dir + ayu_file_list[0]
    else:
        return None

def load_ayu_progress(progress_file):
    progress_status_dict = None
    with open(progress_file, 'rb') as in_handle:
        progress_status_dict = pickle.load(in_handle)
    return progress_status_dict

def get_ayu_status():
    ayu_status_file = find_ayu_status_file(args.out_dir)
    if ayu_status_file is None:
        print('Not able to find an ayu status file in folder {}. Please check the path and try again.')
        return (None, None)
    progress_status_dict = load_ayu_progress(ayu_status_file)
    return (ayu_status_file, progress_status_dict)

def save_ayu_progress(progress_file, progress_status_dict):
    with open(progress_file, 'wb') as out_handle:
        pickle.dump(progress_status_dict, out_handle)

def remove_file(*files_to_remove):
    for filename in files_to_remove:
        try:
            os.remove(filename)
        except FileNotFoundError:
            pass


## LOAD EXTERNAL FILES
def load_tmbed_file(tmbed_input, check_completeness = False):

    ayu_status_file, progress_status_dict = get_ayu_status()
    if progress_status_dict is None: return None

    parsed_tmbed_file = ayu.ex_programs_processing.process_tmbed_file(tmbed_input, args.out_dir)
    if progress_status_dict['tmbed_files'] is None:
        progress_status_dict['tmbed_files'] = [parsed_tmbed_file]
    else:
        progress_status_dict['tmbed_files'].append(parsed_tmbed_file)
    
    save_ayu_progress(ayu_status_file, progress_status_dict)

def load_signalp_file(signalp_input, check_completeness = False):
    ayu_status_file, progress_status_dict = get_ayu_status()
    if progress_status_dict is None: return None

    parsed_signalp_file = ayu.ex_programs_processing.process_signalp_file(signalp_input, args.out_dir)
    if progress_status_dict['signalp_files'] is None:
        progress_status_dict['signalp_files'] = [parsed_signalp_file]
    else:
        progress_status_dict['signalp_files'].append(parsed_signalp_file)
    
    save_ayu_progress(ayu_status_file, progress_status_dict)

def load_ipc2_file(ipc2_input, check_completeness = False):
    ayu_status_file, progress_status_dict = get_ayu_status()
    if progress_status_dict is None: return None

    parsed_ipc2_file = ayu.ex_programs_processing.process_ipc2_file(ipc2_input, args.out_dir)
    if progress_status_dict['ipc2_files'] is None:
        progress_status_dict['ipc2_files'] = [parsed_ipc2_file]
    else:
        progress_status_dict['ipc2_files'].append(parsed_ipc2_file)
    
    save_ayu_progress(ayu_status_file, progress_status_dict)

def check_completeness(extr_type, out_file = None):
    #extr_type is one of 'tmbed_files', 'signalp_files', 'ipc2_files'. Has to be str
    ayu_status_file, progress_status_dict = get_ayu_status()
    if progress_status_dict is None: return None

    extr_seq_set = set([])
    for extr_file in progress_status_dict[extr_type]:
        extr_df = pd.read_csv(extr_file, sep = '\t')
        extr_seq_set = extr_seq_set.union(set(extr_df['prot_ID']))
    
    if len(progress_status_dict['seq_set'] - extr_seq_set) == 0:
        print('All seqs loaded in ayu have {} information'.format(extr_type))
        return set([])
    else:
        print('{} seqs in Ayu do not have {} information'.format(len(progress_status_dict['seq_set'] - extr_seq_set), extr_file))
        if out_file is not None:
            with open(out_file, 'w') as out_handle:
                for item in progress_status_dict['seq_set'] - extr_seq_set:
                    out_handle.write(item + '\n')
            print('IDs of sequences without information have been stored in {}'.format(out_file))
        return progress_status_dict['seq_set'] - extr_seq_set

def check_for_alias(extr_file):
    ayu_status_file, progress_status_dict = get_ayu_status()
    if progress_status_dict is None: return None
    alias_set = set([])
    alias_dict = {}
    with open(progress_status_dict['alias_mapping']) as in_handle:
        for line in in_handle:
            splitLine = line.rstrip('\n').split('\t')
            alias_dict[splitLine[1]] = splitLine[0]
            alias_set.append()
    
    extr_df = pd.read_csv(extr_file, sep = '\t')
    prot_id_set = set(extr_df['prot_ID'])

    def subs_prot_id(x, alias_dict=alias_dict):
        try:
            return alias_dict[x]
        except KeyError:
            return x

    if set(alias_set).intersection(prot_id_set) > 0: pass
    elif set(alias_dict.keys()).intersection(prot_id_set) > 0:
        extr_df['prot_ID'] = extr_df['prot_ID'].apply(subs_prot_id)

    extr_df.write_csv(extr_file + '.alias', sep = '\t', index=None)

    os.remove(extr_file)
    return extr_file + '.alias'

## CALCULATE PROTEIN FEATURES
progress_status_file = None
if not os.path.isdir(args.out_dir):
    os.mkdir(args.out_dir)
else:
    ayu_file_list = [x for x in os.listdir(args.out_dir) if x.split('.')[-1] == 'ayu']
    if len(ayu_file_list) == 1:
        progress_status_file = args.out_dir + ayu_file_list[0]
print(progress_status_file)
progress_status_dict = {'prefilter':None,
                       'alias_fasta':None,
                       'alias_mapping':None,
                       'final_fasta_files':None,
                       'seq_set':None,
                       'tmbed_files':None,
                       'signalp_files':None,
                       'ipc2_files':None
                       }
print(progress_status_dict)
if progress_status_file is None:
    progress_status_file = args.out_dir + 'ayu.{}.status.ayu'.format(os.getpid())
    save_ayu_progress(progress_status_file, progress_status_dict)
else:
    with open(progress_status_file, 'rb') as in_handle:
        progress_status_dict = pickle.load(in_handle)
print(progress_status_dict)


def run_preprocessing(progress_status_dict):
    if progress_status_dict['prefilter'] is None:
        print('Preprocessing files...',end='')
        ayu_preproc_fasta = args.out_dir + 'ayu.{}.preproc.faa'.format(os.getpid())
        ayu_preproc_rejected = args.out_dir + 'ayu.{}.preproc_rejected.txt'.format(os.getpid())
        progress_status_dict['prefilter'] = ayu.preprocessing.process_fasta_files(args.input_file, ayu_preproc_fasta, ayu_preproc_rejected)
        save_ayu_progress(progress_status_file, progress_status_dict)
    else:
        print('Loaded previous preprocessing')

    if progress_status_dict['alias_mapping'] is None:
        print('Processing aliases...', end='')
        ayu_alias_fasta_original = args.out_dir + 'ayu.{}.alias.faa'.format(os.getpid())
        ayu_mapping = args.out_dir + 'ayu.{}.alias_mapping.tsv'.format(os.getpid())
        progress_status_dict['alias_fasta'], progress_status_dict['alias_mapping'] = ayu.preprocessing.give_aliases(
            progress_status_dict['prefilter'], ayu_alias_fasta_original, ayu_mapping)
        save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    else:
        print('Loaded previous aliases')

    if progress_status_dict['final_fasta_files'] is None:
        print('Dividing files into chunks...', end='')
        ayu_alias_fasta_prefix = args.out_dir + 'ayu.{}.alias'.format(os.getpid())
        ayu_fasta_file_list = ayu.preprocessing.divide_fasta_files(progress_status_dict['alias_fasta'], ayu_alias_fasta_prefix)
        print('file divided into {} chunks'.format(len(ayu_fasta_file_list)))
        progress_status_dict['final_fasta_files'] = {}
        for file_name in ayu_fasta_file_list:
            progress_status_dict['final_fasta_files'][file_name] = {'aa_counts':None,
                                                                'aa_counts_ilr':None,
                                                                'dp_counts':None,
                                                                'dp_counts_ilr':None,
                                                                'protein_costs':None,
                                                                'pqso':None,
                                                                'pqso_ilr':None,
                                                                'ppaac':None,
                                                                'ppaac_ilr':None,
                                                                'tmbed':None,
                                                                'sp':None
                                                                }
        remove_file(progress_status_dict['alias_fasta'])
        save_ayu_progress(progress_status_file, progress_status_dict)
    else:
        print('Loaded previous chunks')
    
    return progress_status_dict

def run_aa_counts(progress_status_dict):
    pass

def run_dp_counts(progress_status_dict):
    pass

def run_prot_costs(progress_status_dict):
    pass

run_preprocessing(progress_status_dict)

for ayu_fasta_file in progress_status_dict['final_fasta_files']:
    print('Processing fasta file {}...'.format(ayu_fasta_file))
    ayu_file_prefix = '.'.join(ayu_fasta_file.split('.')[:-1])
    
    if progress_status_dict['final_fasta_files'][ayu_fasta_file]['aa_counts'] is None:
        aa_counts_file = ayu_file_prefix + '.AA_counts.tsv'
        print('\tExtracting protein features (AA Counts)... ', end='')
        progress_status_dict['final_fasta_files'][ayu_fasta_file]['aa_counts'] = ayu.protein_features.process_aa_counts(ayu_fasta_file, 
            aa_counts_file, args.threads)
        save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    else:
        print('\tLoading AA Counts from ')
    if progress_status_dict['final_fasta_files'][ayu_fasta_file]['aa_counts_ilr'] is None:
        print('\tClosure + ILR Conversion for AA Counts...', end='')
        aa_closure_file = progress_status_dict['final_fasta_files'][ayu_fasta_file]['aa_counts'] + '.CL'
        aa_closure_file = ayu.ilr_conversion.process_file_parallel_closure(progress_status_dict['final_fasta_files'][ayu_fasta_file]['aa_counts'], 
                                                                           aa_closure_file, args.threads)
        aa_ilr_file = aa_closure_file + '.ILR'
        progress_status_dict['final_fasta_files'][ayu_fasta_file]['aa_counts_ilr'] = ayu.ilr_conversion.process_file_parallel_ilr(aa_closure_file, aa_ilr_file, args.threads)
        remove_file(progress_status_dict['final_fasta_files'][ayu_fasta_file]['aa_counts'], aa_closure_file)
        save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    
    if progress_status_dict['final_fasta_files'][ayu_fasta_file]['dp_counts'] is None:
        dp_counts_file = ayu_file_prefix + '.DP_counts.tsv'
        print('\tExtracting protein features (DP Counts)...', end='')
        progress_status_dict['final_fasta_files'][ayu_fasta_file]['dp_counts'] = ayu.protein_features.process_dp_counts(ayu_fasta_file, 
            dp_counts_file, args.threads)
        save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    if progress_status_dict['final_fasta_files'][ayu_fasta_file]['dp_counts_ilr'] is None:
        print('\tClosure + ILR Conversion for DP Counts...', end='')
        dp_closure_file = progress_status_dict['final_fasta_files'][ayu_fasta_file]['dp_counts'] + '.CL'
        dp_comp_file = ayu.ilr_conversion.process_file_parallel_closure(progress_status_dict['final_fasta_files'][ayu_fasta_file]['dp_counts'], 
                                                                        dp_closure_file, args.threads)
        dp_ilr_file = dp_closure_file + '.ILR'
        progress_status_dict['final_fasta_files'][ayu_fasta_file]['dp_counts_ilr'] = ayu.ilr_conversion.process_file_parallel_ilr(dp_closure_file, dp_ilr_file, args.threads)
        remove_file(progress_status_dict['final_fasta_files'][ayu_fasta_file]['dp_counts'], dp_closure_file)
        save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')

    if progress_status_dict['final_fasta_files'][ayu_fasta_file]['protein_costs'] is None:
        protein_costs_file = ayu_file_prefix + '.prot_costs.tsv'
        print('\tExtracting protein features (Protein costs)...', end='')
        progress_status_dict['final_fasta_files'][ayu_fasta_file]['protein_costs'] = ayu.protein_features.process_protein_costs(ayu_fasta_file, protein_costs_file, args.threads)
        save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')

    if progress_status_dict['final_fasta_files'][ayu_fasta_file]['pqso'] is None:
        pqso_file = ayu_file_prefix + '.pQSO.tsv'
        print('\tExtracting protein features (Partial QSO)...', end='')
        progress_status_dict['final_fasta_files'][ayu_fasta_file]['pqso'] = ayu.protein_features.process_pqso(ayu_fasta_file, pqso_file, args.threads, 20)
        save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    
    if progress_status_dict['final_fasta_files'][ayu_fasta_file]['pqso_ilr'] is None:
        print('\tClosure + ILR Conversion for partial QSO...', end='')
        pqso_closure_file = progress_status_dict['final_fasta_files'][ayu_fasta_file]['pqso'] + '.CL'
        pqso_closure_file = ayu.ilr_conversion.process_file_parallel2_closure(progress_status_dict['final_fasta_files'][ayu_fasta_file]['pqso'], 
                                                                              pqso_closure_file, args.threads)
        pqso_ilr_file = pqso_closure_file + '.ILR'
        progress_status_dict['final_fasta_files'][ayu_fasta_file]['pqso_ilr'] = ayu.ilr_conversion.process_file_parallel_ilr(pqso_closure_file, 
                                                                                pqso_ilr_file, args.threads)
        remove_file(progress_status_dict['final_fasta_files'][ayu_fasta_file]['pqso'], pqso_closure_file)
        save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')

    if progress_status_dict['final_fasta_files'][ayu_fasta_file]['ppaac'] is None:
        ppaac_file = ayu_file_prefix + '.pPAAC.tsv'
        print('\tExtracting protein features (Partial PAAC)...', end='')
        progress_status_dict['final_fasta_files'][ayu_fasta_file]['ppaac'] = ayu.protein_features.process_ppaac(progress_status_dict['final_fasta_files'][ayu_fasta_file], ppaac_file, args.threads, 20)
        save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')

    if progress_status_dict['final_fasta_files'][ayu_fasta_file]['ppaac_ilr'] is None:
        print('\tClosure + ILR Conversion for partial PAAC...', end='')
        ppaac_closure_file = progress_status_dict['final_fasta_files'][ayu_fasta_file]['ppaac'] + '.CL'
        ppaac_closure_file = ayu.ilr_conversion.process_file_parallel2_closure(progress_status_dict['final_fasta_files'][ayu_fasta_file]['ppaac'],
                                                                            ppaac_closure_file, args.threads)
        ppaac_ilr_file = ppaac_closure_file + '.ILR'
        progress_status_dict['final_fasta_files'][ayu_fasta_file]['ppaac_ilr'] = ayu.ilr_conversion.process_file_parallel_ilr(ppaac_closure_file, ppaac_ilr_file, args.threads)
        remove_file(ppaac_file, ppaac_closure_file)
        save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')

    





