#!/usr/bin/python3

import argparse
import os
import pickle
import pandas as pd
import ayu.preprocessing
import ayu.protein_features

import ayu.ilr_conversion
import ayu.ex_programs_processing
import ayu.prediction


parser = argparse.ArgumentParser()
subparser = parser.add_subparsers(dest='operation')
parser_preproc = subparser.add_parser('preprocess', help='Create an ayu folder and calculate internal protein features. Run this first!')
parser_preproc.add_argument('input_fasta', help='Fasta file')
parser_preproc.add_argument('out_dir', help='Output directory')
parser_preproc.add_argument('--threads', type=int, default=8, help='number of threads for features that allow multiprocessing (default=8)')

parser_runtmbed = subparser.add_parser('run_tmbed', help='Run TMBed with sequences from the Ayu folder.')
parser_runtmbed.add_argument('out_dir', help = 'Ayu project folder (created by "ayu preprocessing")')
parser_runtmbed.add_argument('--tmbed_path', default=None, help='path to TMBed executable. e.g. "/home/usr/bin/tmbed"')

parser_loadtmbed = subparser.add_parser('load_tmbed', help= 'Load TMBed data from an external file.')
parser_loadtmbed.add_argument('input_file', help='TMBed file')
parser_loadtmbed.add_argument('out_dir', help = 'Ayu project folder (created by "ayu preprocessing")')

parser_runsignalp= subparser.add_parser('run_tmbed', help='Run SignalP6 with sequences from the Ayu folder.')
parser_runsignalp.add_argument('out_dir', help = 'Ayu project folder (created by "ayu preprocessing")')
parser_runsignalp.add_argument('--signalp6_path', default=None, help='path to SignalP6 executable. e.g. "/home/usr/bin/signalp6"')

parser_loadsignalp = subparser.add_parser('load_signalp6', help = 'Load SignalP6 data from an external file.')
parser_loadsignalp.add_argument('input_file', help = 'SignalP6 file')
parser_loadsignalp.add_argument('out_dir', help = 'Ayu project folder (created by "ayu preprocessing")')

parser_runipc2= subparser.add_parser('run_ipc2', help='Run IPC2 with sequences from the Ayu folder.')
parser_runipc2.add_argument('out_dir', help = 'Ayu project folder (created by "ayu preprocessing")')
parser_runipc2.add_argument('--ipc2_path', default=None, help='path to IPC2 executable. e.g. "/home/usr/bin/ipc2/ipc2_protein_svr_predictor.py"')
parser_runipc2.add_argument('--model_path', required=True, help='path to IPC2 executable. e.g. "/home/usr/bin/ipc2/models/IPC2_protein_75_SVR_19.pickle"')

parser_loadipc2 = subparser.add_parser('load_ipc2', help = 'Load IPC 2.0 data from an external file.')
parser_loadipc2.add_argument('input_file', 'IPC 2.0 fasta file')
parser_loadipc2.add_argument('out_dir', help = 'Ayu project folder (created by "ayu preprocessing")')

parser_predict = subparser.add_parser('predict', help = 'Predict subcellular localization.')
parser_predict.add_argument('out_dir', help = 'Ayu project folder (created by "ayu preprocessing")')
parser_predict.add_argument('out_file', help='Output TSV file')

args = parser.parse_args()
args.out_dir = args.out_dir.rstrip('/') + '/'

## HELP SCRIPTS

## LOAD EXTERNAL FILES

def run_tmbed():
    ayu_status_file, progress_status_dict = ayu.preprocessing.get_ayu_status(args.out_dir)
    ayu_fasta_file_list = [x for x in progress_status_dict['final_ayu_files'] if progress_status_dict['final_ayu_files'][x]['transmemb'] == None]
    tmbed_raw_file_list = ayu.ex_programs_processing.run_tmbed(args.out_dir, ayu_fasta_file_list, tmbed_path=args.tmbed_path)
    for tmbed_raw_file in tmbed_raw_file_list:
        parsed_tmbed_file = ayu.ex_programs_processing.process_tmbed_file(tmbed_raw_file, args.out_dir)
        ayu.ex_programs_processing.save_tmbed_file_in_ayu(parsed_tmbed_file, args.out_dir)

    if len(tmbed_raw_file_list) != len(ayu_fasta_file_list):
        print('Some fasta files have not been processed. Please check the error log and run the command again.')

def load_tmbed_file(tmbed_input):
    ayu_status_file, progress_status_dict = ayu.preprocessing.get_ayu_status(args.out_dir)
    if progress_status_dict is None: return None

    parsed_tmbed_file = ayu.ex_programs_processing.process_tmbed_file(tmbed_input, args.out_dir)
    ayu.ex_programs_processing.save_tmbed_file_in_ayu(parsed_tmbed_file, args.out_dir)

def run_signalp6():
    ayu_status_file, progress_status_dict = ayu.preprocessing.get_ayu_status(args.out_dir)
    ayu_fasta_file_list = [x for x in progress_status_dict['final_ayu_files'] if progress_status_dict['final_ayu_files'][x]['sp'] == None]
    signalp6_raw_file_list = ayu.ex_programs_processing.run_signalp6(args.out_dir, ayu_fasta_file_list, signalp6_path=args.signalp6_path)
    for signalp6_raw_file in signalp6_raw_file_list:
        parsed_signalp6_file = ayu.ex_programs_processing.process_signalp6_file(signalp6_raw_file, args.out_dir)
        ayu.ex_programs_processing.save_signalp6_file_in_ayu(parsed_signalp6_file, args.out_dir)

    if len(signalp6_raw_file_list) != len(ayu_fasta_file_list):
        print('Some fasta files have not been processed. Please check the error log and run the command again.')

def load_signalp6_file(signalp_input):
    ayu_status_file, progress_status_dict = ayu.preprocessing.get_ayu_status(args.out_dir)
    if progress_status_dict is None: return None

    parsed_sp_file = ayu.ex_programs_processing.process_signalp6_file(signalp_input, args.out_dir)
    ayu.ex_programs_processing.save_signalp6_file_in_ayu(parsed_sp_file, args.out_dir)

def run_ipc2():
    ayu_status_file, progress_status_dict = ayu.preprocessing.get_ayu_status(args.out_dir)
    ayu_fasta_file_list = [x for x in progress_status_dict['final_ayu_files'] if progress_status_dict['final_ayu_files'][x]['pi'] == None]
    ipc2_raw_file_list = ayu.ex_programs_processing.run_ipc2(args.out_dir, ayu_fasta_file_list, 
                                                                 ipc2_path=args.ipc2_path, model_path=args.model_path)
    for ipc2_raw_file in ipc2_raw_file_list:
        parsed_ipc2_file = ayu.ex_programs_processing.process_ipc2_file(ipc2_raw_file, args.out_dir)
        ayu.ex_programs_processing.save_ipc2_file_in_ayu(parsed_ipc2_file, args.out_dir)

    if len(ipc2_raw_file_list) != len(ayu_fasta_file_list):
        print('Some fasta files have not been processed. Please check the error log and run the command again.')

def load_ipc2_file(ipc2_input):
    ayu_status_file, progress_status_dict = ayu.preprocessing.get_ayu_status(args.out_dir)
    if progress_status_dict is None: return None

    parsed_pi_file = ayu.ex_programs_processing.process_ipc2_file(ipc2_input, args.out_dir)
    ayu.ex_programs_processing.save_ipc2_file_in_ayu(parsed_pi_file, args.out_dir)

def check_completeness(extr_type, out_file = None):
    #extr_type is one of 'tmbed_files', 'signalp_files', 'ipc2_files'. Has to be str
    ayu_status_file, progress_status_dict = ayu.preprocessing.get_ayu_status(args.out_dir)
    if progress_status_dict is None: return None

    extr_seq_set = set([])
    for extr_file in progress_status_dict[extr_type]:
        extr_df = pd.read_csv(extr_file, sep = '\t')
        extr_seq_set = extr_seq_set.union(set(extr_df['prot_ID']))
    
    if len(progress_status_dict['seq_set'] - extr_seq_set) == 0:
        print('All seqs loaded in ayu have {} information'.format(extr_type))
        return set([])
    else:
        print('{} seqs in Ayu do not have {} information'.format(len(progress_status_dict['seq_set'] - extr_seq_set), extr_file))
        if out_file is not None:
            with open(out_file, 'w') as out_handle:
                for item in progress_status_dict['seq_set'] - extr_seq_set:
                    out_handle.write(item + '\n')
            print('IDs of sequences without information have been stored in {}'.format(out_file))
        return progress_status_dict['seq_set'] - extr_seq_set

def check_for_alias(extr_file):
    ayu_status_file, progress_status_dict = ayu.preprocessing.get_ayu_status(args.out_dir)
    if progress_status_dict is None: return None
    alias_set = set([])
    alias_dict = {}
    with open(progress_status_dict['alias_mapping']) as in_handle:
        for line in in_handle:
            splitLine = line.rstrip('\n').split('\t')
            alias_dict[splitLine[1]] = splitLine[0]
            alias_set.append()
    
    extr_df = pd.read_csv(extr_file, sep = '\t')
    prot_id_set = set(extr_df['prot_ID'])

    def subs_prot_id(x, alias_dict=alias_dict):
        try:
            return alias_dict[x]
        except KeyError:
            return x

    if set(alias_set).intersection(prot_id_set) > 0: pass
    elif set(alias_dict.keys()).intersection(prot_id_set) > 0:
        extr_df['prot_ID'] = extr_df['prot_ID'].apply(subs_prot_id)

    extr_df.write_csv(extr_file + '.alias', sep = '\t', index=None)

    os.remove(extr_file)
    return extr_file + '.alias'

## CALCULATE PROTEIN FEATURES

def run_preprocessing(progress_status_dict):
    if progress_status_dict['prefilter'] is None:
        print('Preprocessing files...',end='')
        ayu_preproc_fasta = args.out_dir + 'ayu.{}.preproc.faa'.format(os.getpid())
        ayu_preproc_rejected = args.out_dir + 'ayu.{}.preproc_rejected.txt'.format(os.getpid())
        progress_status_dict['prefilter'] = ayu.preprocessing.process_fasta_files(args.input_fasta, ayu_preproc_fasta, ayu_preproc_rejected)
        progress_status_dict['rejected_preproc'] = ayu_preproc_rejected
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
    else:
        print('Loaded previous preprocessing')

    if progress_status_dict['alias_mapping'] is None:
        print('Processing aliases...', end='')
        ayu_alias_fasta_original = args.out_dir + 'ayu.{}.alias.faa'.format(os.getpid())
        ayu_mapping = args.out_dir + 'ayu.{}.alias_mapping.tsv'.format(os.getpid())
        progress_status_dict['alias_fasta'], progress_status_dict['alias_mapping'] = ayu.preprocessing.give_aliases(
            progress_status_dict['prefilter'], ayu_alias_fasta_original, ayu_mapping)
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    else:
        print('Loaded previous aliases')

    if progress_status_dict['final_ayu_files'] is None:
        print('Dividing files into chunks...', end='')
        ayu_alias_fasta_prefix = args.out_dir + 'ayu.{}.alias'.format(os.getpid())
        ayu_fasta_file_list = ayu.preprocessing.divide_fasta_files(progress_status_dict['alias_fasta'], ayu_alias_fasta_prefix)
        print('\tfile divided into {} chunks'.format(len(ayu_fasta_file_list)))
        progress_status_dict['final_ayu_files'] = {}
        for file_name in ayu_fasta_file_list:
            seq_set = ayu.preprocessing.get_seq_set(file_name)
            progress_status_dict['final_ayu_files'][file_name] = {
                                                                'seq_set':seq_set,
                                                                'aa_counts':None,
                                                                'ilr_aa_counts':None,
                                                                'dp_counts':None,
                                                                'ilr_dp_counts':None,
                                                                'protein_costs':None,
                                                                'pqso':None,
                                                                'ilr_pqso':None,
                                                                'ppaac':None,
                                                                'ilr_ppaac':None,
                                                                'transmemb':None,
                                                                'transmemb_set':set([]),
                                                                'sp':None,
                                                                'sp_set':set([]),
                                                                'pi':None,
                                                                'pi_set':set([])
                                                                }
        ayu.preprocessing.remove_file(progress_status_dict['alias_fasta'])
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
    else:
        print('Loaded previous chunks')
    
    return progress_status_dict

def run_aa_counts(progress_status_dict, ayu_fasta_file):
    ayu_file_prefix = '.'.join(ayu_fasta_file.split('.')[:-1])
    if progress_status_dict['final_ayu_files'][ayu_fasta_file]['aa_counts'] is None:
        aa_counts_file = ayu_file_prefix + '.AA_counts.tsv'
        print('\tExtracting protein features (AA Counts)... ', end='')
        progress_status_dict['final_ayu_files'][ayu_fasta_file]['aa_counts'] = ayu.protein_features.process_aa_counts(ayu_fasta_file, 
            aa_counts_file, args.threads)
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    else:
        print('\tLoading AA Counts from {}'.format(progress_status_dict['final_ayu_files'][ayu_fasta_file]['aa_counts']))
    
    if progress_status_dict['final_ayu_files'][ayu_fasta_file]['ilr_aa_counts'] is None:
        print('\tClosure + ILR Conversion (AA Counts)...', end='')
        aa_closure_file = progress_status_dict['final_ayu_files'][ayu_fasta_file]['aa_counts'] + '.CL'
        aa_closure_file = ayu.ilr_conversion.process_file_parallel_closure(progress_status_dict['final_ayu_files'][ayu_fasta_file]['aa_counts'], 
                                                                           aa_closure_file, args.threads)
        aa_ilr_file = aa_closure_file + '.ILR'
        progress_status_dict['final_ayu_files'][ayu_fasta_file]['ilr_aa_counts'] = ayu.ilr_conversion.process_file_parallel_ilr(aa_closure_file, aa_ilr_file, args.threads)
        ayu.preprocessing.remove_file(progress_status_dict['final_ayu_files'][ayu_fasta_file]['aa_counts'], aa_closure_file)
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    else:
        print('\tLoading ILR-converted AA Counts from {}'.format(progress_status_dict['final_ayu_files'][ayu_fasta_file]['ilr_aa_counts']))

def run_dp_counts(progress_status_dict, ayu_fasta_file):
    ayu_file_prefix = '.'.join(ayu_fasta_file.split('.')[:-1])
    if progress_status_dict['final_ayu_files'][ayu_fasta_file]['dp_counts'] is None:
        dp_counts_file = ayu_file_prefix + '.DP_counts.tsv'
        print('\tExtracting protein features (DP Counts)...', end='')
        progress_status_dict['final_ayu_files'][ayu_fasta_file]['dp_counts'] = ayu.protein_features.process_dp_counts(ayu_fasta_file, 
            dp_counts_file, args.threads)
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    else:
        print('\tLoading DP Counts from {}'.format(progress_status_dict['final_ayu_files'][ayu_fasta_file]['dp_counts']))

    if progress_status_dict['final_ayu_files'][ayu_fasta_file]['ilr_dp_counts'] is None:
        print('\tClosure + ILR Conversion (DP Counts)...', end='')
        dp_closure_file = progress_status_dict['final_ayu_files'][ayu_fasta_file]['dp_counts'] + '.CL'
        dp_comp_file = ayu.ilr_conversion.process_file_parallel_closure(progress_status_dict['final_ayu_files'][ayu_fasta_file]['dp_counts'], 
                                                                        dp_closure_file, args.threads)
        dp_ilr_file = dp_closure_file + '.ILR'
        progress_status_dict['final_ayu_files'][ayu_fasta_file]['ilr_dp_counts'] = ayu.ilr_conversion.process_file_parallel_ilr(dp_closure_file, dp_ilr_file, args.threads)
        ayu.preprocessing.remove_file(progress_status_dict['final_ayu_files'][ayu_fasta_file]['dp_counts'], dp_closure_file)
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    else:
        print('\tLoading ILR-converted DP Counts from {}'.format(progress_status_dict['final_ayu_files'][ayu_fasta_file]['ilr_dp_counts']))

def run_prot_costs(progress_status_dict, ayu_fasta_file):
    ayu_file_prefix = '.'.join(ayu_fasta_file.split('.')[:-1])
    if progress_status_dict['final_ayu_files'][ayu_fasta_file]['protein_costs'] is None:
        protein_costs_file = ayu_file_prefix + '.prot_costs.tsv'
        print('\tExtracting protein features (Protein costs)...', end='')
        progress_status_dict['final_ayu_files'][ayu_fasta_file]['protein_costs'] = ayu.protein_features.process_protein_costs(ayu_fasta_file, protein_costs_file, args.threads)
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    else:
        print('\tLoading protein costs file from {}'.format(progress_status_dict['final_ayu_files'][ayu_fasta_file]['protein_costs']))

def run_pqso(progress_status_dict, ayu_fasta_file):
    ayu_file_prefix = '.'.join(ayu_fasta_file.split('.')[:-1])
    if progress_status_dict['final_ayu_files'][ayu_fasta_file]['pqso'] is None:
        pqso_file = ayu_file_prefix + '.pQSO.tsv'
        print('\tExtracting protein features (Partial QSO)...', end='')
        progress_status_dict['final_ayu_files'][ayu_fasta_file]['pqso'] = ayu.protein_features.process_pqso(ayu_fasta_file, pqso_file, args.threads, 20)
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    else:
        print('\tLoading pQSO file from {}'.format(progress_status_dict['final_ayu_files'][ayu_fasta_file]['pqso']))
    
    if progress_status_dict['final_ayu_files'][ayu_fasta_file]['ilr_pqso'] is None:
        print('\tClosure + ILR Conversion for partial QSO...', end='')
        pqso_closure_file = progress_status_dict['final_ayu_files'][ayu_fasta_file]['pqso'] + '.CL'
        pqso_closure_file = ayu.ilr_conversion.process_file_parallel_closure(progress_status_dict['final_ayu_files'][ayu_fasta_file]['pqso'], 
                                                                              pqso_closure_file, args.threads)
        pqso_ilr_file = pqso_closure_file + '.ILR'
        progress_status_dict['final_ayu_files'][ayu_fasta_file]['ilr_pqso'] = ayu.ilr_conversion.process_file_parallel_ilr(pqso_closure_file, 
                                                                                pqso_ilr_file, args.threads)
        ayu.preprocessing.remove_file(progress_status_dict['final_ayu_files'][ayu_fasta_file]['pqso'], pqso_closure_file)
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    else:
        print('\tLoading ILR-converted pQSO file from {}'.format(progress_status_dict['final_ayu_files'][ayu_fasta_file]['ilr_pqso']))

def run_ppaac(progress_status_dict, ayu_fasta_file):
    ayu_file_prefix = '.'.join(ayu_fasta_file.split('.')[:-1])
    if progress_status_dict['final_ayu_files'][ayu_fasta_file]['ppaac'] is None:
        ppaac_file = ayu_file_prefix + '.pPAAC.tsv'
        print('\tExtracting protein features (Partial PAAC)...', end='')
        progress_status_dict['final_ayu_files'][ayu_fasta_file]['ppaac'] = ayu.protein_features.process_ppaac(ayu_fasta_file, 
                                                                                                                ppaac_file, args.threads, 20)
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    else:
        print('\tLoading pPAAC file from {}'.format(progress_status_dict['final_ayu_files'][ayu_fasta_file]['ppaac']))

    if progress_status_dict['final_ayu_files'][ayu_fasta_file]['ilr_ppaac'] is None:
        print('\tClosure + ILR Conversion for partial PAAC...', end='')
        ppaac_closure_file = progress_status_dict['final_ayu_files'][ayu_fasta_file]['ppaac'] + '.CL'
        ppaac_closure_file = ayu.ilr_conversion.process_file_parallel_closure(progress_status_dict['final_ayu_files'][ayu_fasta_file]['ppaac'],
                                                                            ppaac_closure_file, args.threads)
        ppaac_ilr_file = ppaac_closure_file + '.ILR'
        progress_status_dict['final_ayu_files'][ayu_fasta_file]['ilr_ppaac'] = ayu.ilr_conversion.process_file_parallel_ilr(ppaac_closure_file, ppaac_ilr_file, args.threads)
        ayu.preprocessing.remove_file(progress_status_dict['final_ayu_files'][ayu_fasta_file]['ppaac'], ppaac_closure_file)
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
        print('\tDone!')
    else:
        print('\tLoading ILR-converted pQSO file from {}'.format(progress_status_dict['final_ayu_files'][ayu_fasta_file]['ilr_pqso']))


if args.operation == 'preprocess':
    progress_status_file = None
    progress_status_dict = {'prefilter':None,
                       'alias_fasta':None,
                       'alias_mapping':None,
                       'final_ayu_files':None,
                       'rejected_preproc':None
                       }
    
    # If there is no project directory, create one
    if not os.path.isdir(args.out_dir):
        os.mkdir(args.out_dir)
        progress_status_file = args.out_dir + 'ayu.{}.status.ayu'.format(os.getpid())
        ayu.preprocessing.save_ayu_progress(progress_status_file, progress_status_dict)
    else:
        progress_status_file, progress_status_dict = ayu.preprocessing.get_ayu_status(args.out_dir)
    
    run_preprocessing(progress_status_dict)

    for ayu_fasta_file in progress_status_dict['final_ayu_files']:
        print('Processing fasta file {}...'.format(ayu_fasta_file))
        run_aa_counts(progress_status_dict, ayu_fasta_file)
        run_dp_counts(progress_status_dict, ayu_fasta_file)
        run_prot_costs(progress_status_dict, ayu_fasta_file)
        run_pqso(progress_status_dict, ayu_fasta_file)
        run_ppaac(progress_status_dict, ayu_fasta_file)

        print('Preprocessing finished.')

if args.operation == 'run_tmbed':
    run_tmbed()

if args.operation == 'load_tmbed':
    load_tmbed_file(args.input_file)

if args.operation == 'run_signalp6':
    run_signalp6()

if args.operation == 'load_signalp6':
    load_signalp6_file(args.input_file)

if args.operation == 'load_ipc2':
    load_ipc2_file(args.input_file)

if args.operation == 'run_ipc2':
    run_ipc2()



if args.operation == 'predict':
    ayu_status_file, progress_status_dict = ayu.preprocessing.get_ayu_status(args.out_dir)
    final_merged_df_list = ayu.preprocessing.merge_dfs(progress_status_dict)
    
    pred_models = ayu.prediction.load_predictor_models()
    raw_pred_file = args.out_dir + 'ayu.raw_preds.{}.tsv'.format(os.getpid())
    for merged_df in final_merged_df_list:
        pred_df = ayu.prediction.run_predictions(merged_df, pred_models)
        ayu.prediction.save_prediction_file(pred_df, raw_pred_file)
    ayu.prediction.modify_prediction_file(raw_pred_file, progress_status_dict, args.out_file)



